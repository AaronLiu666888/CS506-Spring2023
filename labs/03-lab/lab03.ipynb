{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 03: KMeans, Clustering, and Distance Metrics\n",
    "\n",
    "In this lab, you will be learning how to use the KMeans algorithm to cluster data and how to use distance metrics to measure the similarity between data points. You will also implement the KMeans algorithm with the provided methods and distance metric methods.\n",
    "\n",
    "_You will also be able to test your methods running the cells provided (you'll see what I mean)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell! \n",
    "#This read method is needed to parse the csv file:\n",
    "\n",
    "import csv\n",
    "\n",
    "def read_csv(csv_file_path):\n",
    "    \"\"\"\n",
    "        Given a path to a csv file, return a matrix (list of lists)\n",
    "        in row major.\n",
    "    \"\"\"\n",
    "    with open(csv_file_path, 'r') as f:\n",
    "        return [[int(cell) if cell.isdigit() else cell for cell in row] for row in csv.reader(f)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete the methods below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `kmeans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def get_centroid(points):\n",
    "    \"\"\"\n",
    "    Accepts a list of points, each with the same number of dimensions.\n",
    "    (points can have more dimensions than 2)\n",
    "    \n",
    "    Returns a new point which is the center of all the points.\n",
    "    \"\"\"\n",
    "    num_points = len(points)\n",
    "    num_dimensions = len(points[0])\n",
    "    centroid = []\n",
    "    \n",
    "    for d in range(num_dimensions):\n",
    "        sum_d = 0\n",
    "        for p in points:\n",
    "            sum_d += p[d]\n",
    "        centroid.append(sum_d / num_points)\n",
    "        \n",
    "    return centroid\n",
    "\n",
    "def get_centroids(dataset, assignments):\n",
    "    \"\"\"\n",
    "    Accepts a dataset and a list of assignments; the indexes \n",
    "    of both lists correspond to each other.\n",
    "    Compute the centroid for each of the assigned groups.\n",
    "    Return `k` centroids in a list\n",
    "    \"\"\"\n",
    "    k = max(assignments) + 1 \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        group_indices = [j for j, assignment in enumerate(assignments) if assignment == i]\n",
    "        group_points = [dataset[j] for j in group_indices]\n",
    "        centroid = get_centroid(group_points)\n",
    "        centroids.append(centroid)\n",
    "        \n",
    "    return centroids\n",
    "\n",
    "def assign_points(data_points, centers):\n",
    "    \"\"\"\n",
    "    This method assigns each point in data_points to the closest center\n",
    "    and returns a list of assignments.\n",
    "    \"\"\"\n",
    "    #NOTE: i did this method for u guys so you can see an example of how \n",
    "    #these variables are used. You can change it if you want.\n",
    "    return [min(range(len(centers)), key=lambda i: distance(point, centers[i])) for point in data_points]\n",
    "\n",
    "\n",
    "def distance(a, b):\n",
    "    \"\"\"\n",
    "    Returns the Euclidean distance between a and b\n",
    "    \"\"\"\n",
    "    if(len(a)!=len(b)):\n",
    "        return ValueError('length of a must equals to length of b')\n",
    "    else:\n",
    "        squared_distance = sum([(ai - bi) ** 2 for ai, bi in zip(a, b)])\n",
    "        return math.sqrt(squared_distance)\n",
    "\n",
    "def distance_squared(a, b):\n",
    "    if(len(a)!=len(b)):\n",
    "        return ValueError('length of a must equals to length of b')\n",
    "    else:\n",
    "        return distance(a,b)**2\n",
    "\n",
    "def cost_function(clustering):\n",
    "    \"\"\"\n",
    "    Accepts a clustering as a dictionary of lists of points.\n",
    "    Returns the cost of the clustering.\n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    for centroid, points in clustering.items():\n",
    "        for point in points:\n",
    "            cost += distance(point, centroid) ** 2\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def generate_k(dataset, k):\n",
    "    \"\"\"\n",
    "    Given `data_set`, which is an array of arrays,\n",
    "    return a random set of k points from the data_set\n",
    "    \"\"\"\n",
    "    random.shuffle(dataset)\n",
    "    return dataset[:k]\n",
    "\n",
    "def generate_k_pp(dataset, k):\n",
    "    \"\"\"\n",
    "    Given `data_set`, which is an array of arrays,\n",
    "    return a random set of k points from the data_set\n",
    "    where points are picked with a probability proportional\n",
    "    to their distance as per kmeans pp\n",
    "    \"\"\"\n",
    "    centroids = [random.choice(dataset)]\n",
    "    for i in range(1, k):\n",
    "        distances = [min([np.linalg.norm(x-c)**2 for c in centroids]) for x in dataset]\n",
    "        probs = distances / np.sum(distances)\n",
    "        cum_probs = np.cumsum(probs)\n",
    "        r = random.random()\n",
    "        for j, cp in enumerate(cum_probs):\n",
    "            if r < cp:\n",
    "                centroids.append(dataset[j])\n",
    "                break\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def _do_lloyds_algo(dataset, k_points):\n",
    "    assignments = assign_points(dataset, k_points)\n",
    "    old_assignments = None\n",
    "    while assignments != old_assignments:\n",
    "        new_centers = get_centroids(dataset, assignments)\n",
    "        old_assignments = assignments\n",
    "        assignments = assign_points(dataset, new_centers)\n",
    "    clustering = defaultdict(list)\n",
    "    for assignment, point in zip(assignments, dataset):\n",
    "        clustering[assignment].append(point)\n",
    "    return clustering\n",
    "\n",
    "\n",
    "def k_means(dataset, k):\n",
    "    if k not in range(1, len(dataset)+1):\n",
    "        raise ValueError(\"lengths must be in [1, len(dataset)]\")\n",
    "    \n",
    "    k_points = generate_k(dataset, k)\n",
    "    return _do_lloyds_algo(dataset, k_points)\n",
    "\n",
    "\n",
    "def k_means_pp(dataset, k):\n",
    "    if k not in range(1, len(dataset)+1):\n",
    "        raise ValueError(\"lengths must be in [1, len(dataset)]\")\n",
    "\n",
    "    k_points = generate_k_pp(dataset, k)\n",
    "    return _do_lloyds_algo(dataset, k_points)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing `kmeans`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the methods provided to see if your `kmeans` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_kmeans_when_k_is_1 passed!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 160\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39m#testing methods\u001b[39;00m\n\u001b[1;32m    159\u001b[0m test_kmeans_when_k_is_1()\n\u001b[0;32m--> 160\u001b[0m test_kmeans_when_k_is_2()\n\u001b[1;32m    161\u001b[0m test_kmeans_when_k_is_3()\n\u001b[1;32m    162\u001b[0m test_kmeans_pp_when_k_is_2()\n",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m, in \u001b[0;36mtest_kmeans_when_k_is_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m expected_clustering2 \u001b[39m=\u001b[39m read_csv(expected2)\n\u001b[1;32m     45\u001b[0m clustering \u001b[39m=\u001b[39m k_means(dataset\u001b[39m=\u001b[39mdataset, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m cost \u001b[39m=\u001b[39m cost_function(clustering)\n\u001b[1;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m     49\u001b[0m     new_clustering \u001b[39m=\u001b[39m k_means(dataset\u001b[39m=\u001b[39mdataset, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 78\u001b[0m, in \u001b[0;36mcost_function\u001b[0;34m(clustering)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m centroid, points \u001b[39min\u001b[39;00m clustering\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     77\u001b[0m     \u001b[39mfor\u001b[39;00m point \u001b[39min\u001b[39;00m points:\n\u001b[0;32m---> 78\u001b[0m         cost \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m distance(point, centroid) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m cost\n",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m, in \u001b[0;36mdistance\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdistance\u001b[39m(a, b):\n\u001b[1;32m     55\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    Returns the Euclidean distance between a and b\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mlen\u001b[39m(a)\u001b[39m!=\u001b[39m\u001b[39mlen\u001b[39;49m(b)):\n\u001b[1;32m     59\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mlength of a must equals to length of b\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "#DO NOT MODIFY THIS CELL!!!!\n",
    "\n",
    "import random\n",
    "import csv\n",
    "#import read\n",
    "\n",
    "def clustered_all_points(clustering, dataset):\n",
    "    points = []\n",
    "    for assignment in clustering:\n",
    "        points += clustering[assignment]\n",
    "    for point in points:\n",
    "        if point not in dataset:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_kmeans_when_k_is_1():\n",
    "    datasetPath = \"tests/test_files/dataset_1.csv\"\n",
    "\n",
    "    random.seed(1)\n",
    "    dataset = read_csv(datasetPath)\n",
    "    expected_clustering = dataset\n",
    "    clustering = k_means(dataset=dataset, k=1)\n",
    "\n",
    "    assert len(clustering.keys()) == 1\n",
    "    assert clustered_all_points(clustering, dataset) is True\n",
    "\n",
    "    clustered = []\n",
    "    for assignment in clustering:\n",
    "        clustered.append(clustering[assignment])\n",
    "    assert clustered == [expected_clustering]\n",
    "\n",
    "    print(\"test_kmeans_when_k_is_1 passed!\")\n",
    "\n",
    "\n",
    "def test_kmeans_when_k_is_2():\n",
    "    datasetPath = \"tests/test_files/dataset_1.csv\"\n",
    "    expected1 = \"tests/test_files/dataset_1_k_is_2_0.csv\"\n",
    "    expected2 = \"tests/test_files/dataset_1_k_is_2_1.csv\"\n",
    "\n",
    "    random.seed(1)\n",
    "    dataset = read_csv(datasetPath)\n",
    "    expected_clustering1 = read_csv(expected1)\n",
    "    expected_clustering2 = read_csv(expected2)\n",
    "    clustering = k_means(dataset=dataset, k=2)\n",
    "    cost = cost_function(clustering)\n",
    "\n",
    "    for _ in range(10):\n",
    "        new_clustering = k_means(dataset=dataset, k=2)\n",
    "        new_cost = cost_function(clustering)\n",
    "        if new_cost < cost:\n",
    "            clustering = new_clustering\n",
    "            cost = new_cost\n",
    "\n",
    "\n",
    "    assert len(clustering.keys()) == 2\n",
    "    assert clustered_all_points(clustering, dataset) is True\n",
    "    clustered = []\n",
    "    for assignment in clustering:\n",
    "        clustered.append(clustering[assignment])\n",
    "    assert clustered == [expected_clustering1, expected_clustering2]\n",
    "\n",
    "    print(\"test_kmeans_when_k_is_2 passed!\")\n",
    "\n",
    "\n",
    "\n",
    "def test_kmeans_when_k_is_3():\n",
    "    datasetPath = \"tests/test_files/dataset_1.csv\"\n",
    "    expected1 = \"tests/test_files/dataset_1_k_is_3_0.csv\"\n",
    "    expected2 = \"tests/test_files/dataset_1_k_is_3_1.csv\"\n",
    "    expected3 = \"tests/test_files/dataset_1_k_is_3_2.csv\"\n",
    "    \n",
    "    random.seed(1)\n",
    "    dataset = read_csv(datasetPath)\n",
    "    expected_clustering1 = read_csv(expected1)\n",
    "    expected_clustering2 = read_csv(expected2)\n",
    "    expected_clustering3 = read_csv(expected3)\n",
    "    clustering = k_means(dataset=dataset, k=3)\n",
    "    cost = cost_function(clustering)\n",
    "\n",
    "    for _ in range(10):\n",
    "        new_clustering = k_means(dataset=dataset, k=3)\n",
    "        new_cost = cost_function(clustering)\n",
    "        if new_cost < cost:\n",
    "            clustering = new_clustering\n",
    "            cost = new_cost\n",
    "\n",
    "    assert len(clustering.keys()) == 3\n",
    "    assert clustered_all_points(clustering, dataset) is True\n",
    "    \n",
    "    print(\"test_kmeans_when_k_is_3 passed!\")\n",
    "\n",
    "    clustered = []\n",
    "    for assignment in clustering:\n",
    "        clustered.append(clustering[assignment])\n",
    "    assert clustered == [expected_clustering1, expected_clustering2, expected_clustering3]\n",
    "\n",
    "\n",
    "def test_kmeans_pp_when_k_is_2():\n",
    "    # read file named dataset_1.csv \n",
    "    datasetPath = \"tests/test_files/dataset_1.csv\"\n",
    "    expected1 = \"tests/test_files/dataset_1_k_is_2_0.csv\"\n",
    "    expected2 = \"tests/test_files/dataset_1_k_is_2_1.csv\"\n",
    "\n",
    "    dataset = read_csv(datasetPath)\n",
    "    expected_clustering1 = read_csv(expected1)\n",
    "    expected_clustering2 = read_csv(expected2)\n",
    "    clustering = k_means_pp(dataset=dataset, k=2)\n",
    "    cost = cost_function(clustering)\n",
    "\n",
    "    for _ in range(10):\n",
    "        new_clustering = k_means_pp(dataset=dataset, k=2)\n",
    "        new_cost = cost_function(clustering)\n",
    "        if new_cost < cost:\n",
    "            clustering = new_clustering\n",
    "            cost = new_cost\n",
    "\n",
    "\n",
    "    assert len(clustering.keys()) == 2\n",
    "    assert clustered_all_points(clustering, dataset) is True\n",
    "    clustered = []\n",
    "    for assignment in clustering:\n",
    "        clustered.append(clustering[assignment])\n",
    "    assert clustered.sort() == [expected_clustering1, expected_clustering2].sort()\n",
    "\n",
    "    print(\"test_kmeans_pp_when_k_is_2 passed!\")\n",
    "\n",
    "def test_kmeans_pp_when_k_is_3():\n",
    "    datasetPath = \"tests/test_files/dataset_1.csv\"\n",
    "    expected1 = \"tests/test_files/dataset_1_k_is_3_0.csv\"\n",
    "    expected2 = \"tests/test_files/dataset_1_k_is_3_1.csv\"\n",
    "    expected3 = \"tests/test_files/dataset_1_k_is_3_2.csv\"\n",
    "    \n",
    "    dataset = read_csv(datasetPath)\n",
    "    expected_clustering1 = read_csv(expected1)\n",
    "    expected_clustering2 = read_csv(expected2)\n",
    "    expected_clustering3 = read_csv(expected3)\n",
    "    clustering = k_means_pp(dataset=dataset, k=3)\n",
    "    cost = cost_function(clustering)\n",
    "\n",
    "    for _ in range(10):\n",
    "        new_clustering = k_means_pp(dataset=dataset, k=3)\n",
    "        new_cost = cost_function(clustering)\n",
    "        if new_cost < cost:\n",
    "            clustering = new_clustering\n",
    "            cost = new_cost\n",
    "\n",
    "    assert len(clustering.keys()) == 3\n",
    "    assert clustered_all_points(clustering, dataset) is True\n",
    "    \n",
    "    clustered = []\n",
    "    for assignment in clustering:\n",
    "        clustered.append(clustering[assignment])\n",
    "    assert clustered.sort() == [expected_clustering1, expected_clustering2, expected_clustering3].sort()\n",
    "\n",
    "    print(\"test_kmeans_pp_when_k_is_3 passed!\")\n",
    "\n",
    "#testing methods\n",
    "test_kmeans_when_k_is_1()\n",
    "test_kmeans_when_k_is_2()\n",
    "test_kmeans_when_k_is_3()\n",
    "test_kmeans_pp_when_k_is_2()\n",
    "test_kmeans_pp_when_k_is_3()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sim`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where you will write your distance metric methods. Sim is short for similarity. You will be implementing the following distance metrics:\n",
    "\n",
    "- Euclidean Distance\n",
    "- Manhattan Distance\n",
    "- Jaccard Distance\n",
    "- Cosine Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: x and y are arrays, but keep in mind you may be given invalid inputs. You will need to handle invalid inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    return np.sqrt(sum([(xi - yi)**2 for xi, yi in zip(x, y)]))\n",
    "\n",
    "def manhattan_dist(x, y):\n",
    "    return sum([abs(xi - yi) for xi, yi in zip(x, y)])\n",
    "\n",
    "def jaccard_dist(x, y):\n",
    "    if not x and not y:\n",
    "        return 0.0\n",
    "    x_set = set(x)\n",
    "    y_set = set(y)\n",
    "    intersection = len(x_set & y_set)\n",
    "    union = len(x_set | y_set)\n",
    "    return 1.0 - float(intersection) / union\n",
    "\n",
    "def cosine_sim(x, y):\n",
    "    norm_x = np.sqrt(sum([xi**2 for xi in x]))\n",
    "    norm_y = np.sqrt(sum([yi**2 for yi in y]))\n",
    "    dot_xy = sum([xi*yi for xi, yi in zip(x, y)])\n",
    "    return dot_xy / (norm_x * norm_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing `sim`\n",
    "\n",
    "Run the methods provided to see if your `sim` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_dist is right!\n",
      "manhattan_dist is right!\n",
      "cosine_sim is right!\n",
      "jaccard_dist is right!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/p_sgdjnx4nn04dlj8mv5ybqh0000gn/T/ipykernel_1116/3423946564.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return dot_xy / (norm_x * norm_y)\n"
     ]
    }
   ],
   "source": [
    "def _generate_rand_point(dimension):\n",
    "    return [random.randrange(1, 1000, 1) for i in range(dimension)]\n",
    "\n",
    "\n",
    "def test_euclidean():\n",
    "    # sanity checks\n",
    "    try:\n",
    "        euclidean_dist([], [])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must not be zero\"\n",
    "    try:\n",
    "        euclidean_dist([0], [0,0])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must be equal\"\n",
    "    \n",
    "    assert euclidean_dist([0,0], [1,0]) == 1\n",
    "    assert euclidean_dist([0,0,0], [1,0,0]) == 1\n",
    "    assert euclidean_dist([0,0,0], [0,0,0]) == 0\n",
    "    assert euclidean_dist([0,0,0], [1,0,0]) == euclidean_dist([1,0,0], [0,0,0])\n",
    "    dimension = random.randint(1, 100)\n",
    "    x = _generate_rand_point(dimension)\n",
    "    # distance from a pt to itself is 0\n",
    "    assert euclidean_dist(x, x) == 0\n",
    "    # distance is always positive\n",
    "    y = _generate_rand_point(dimension)\n",
    "    assert euclidean_dist(x, y) >= 0\n",
    "    # distance is symmetric\n",
    "    assert euclidean_dist(x, y) == euclidean_dist(y, x)\n",
    "    # triangle inequality\n",
    "    z = _generate_rand_point(dimension)\n",
    "    assert euclidean_dist(x, y) <= euclidean_dist(x, z) + euclidean_dist(z, y)\n",
    "\n",
    "    print(\"euclidean_dist is right!\")\n",
    "\n",
    "def test_manhattan():\n",
    "    # sanity checks\n",
    "    try:\n",
    "        manhattan_dist([], [])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must not be zero\"\n",
    "    try:\n",
    "        manhattan_dist([0], [0,0])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must be equal\"\n",
    "    \n",
    "    assert manhattan_dist([0,0], [1,1]) == 2\n",
    "    assert manhattan_dist([0,0,0], [1,1,1]) == 3\n",
    "    dimension = random.randint(1, 100)\n",
    "    x = _generate_rand_point(dimension)\n",
    "    # distance from a pt to itself is 0\n",
    "    assert manhattan_dist(x, x) == 0\n",
    "    # distance is always positive\n",
    "    y = _generate_rand_point(dimension)\n",
    "    assert manhattan_dist(x, y) >= 0\n",
    "    # distance is symmetric\n",
    "    assert manhattan_dist(x, y) == manhattan_dist(y, x)\n",
    "    # triangle inequality\n",
    "    z = _generate_rand_point(dimension)\n",
    "    assert manhattan_dist(x, y) <= manhattan_dist(x, z) + manhattan_dist(z, y)\n",
    "\n",
    "    print(\"manhattan_dist is right!\")\n",
    "\n",
    "def test_cosine():\n",
    "    try:\n",
    "        cosine_sim([], [])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must not be zero\"\n",
    "    try:\n",
    "        cosine_sim([0], [0,0])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must be equal\"\n",
    "    \n",
    "    assert cosine_sim([1,0], [1,0]) == 1\n",
    "    assert cosine_sim([0,1,0], [1,0,0]) == 0\n",
    "\n",
    "    print(\"cosine_sim is right!\")\n",
    "\n",
    "\n",
    "def test_jaccard():\n",
    "    # sanity checks\n",
    "    try:\n",
    "        jaccard_dist([], [])\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"lengths must not be zero\"\n",
    "    \n",
    "    assert jaccard_dist([0,0], [1,0]) == .5\n",
    "    assert jaccard_dist([0,0,0], [1,1,1]) == 1\n",
    "    dimension = random.randint(1, 100)\n",
    "    x = _generate_rand_point(dimension)\n",
    "    # distance from a pt to itself is 0\n",
    "    assert jaccard_dist(x, x) == 0\n",
    "    # distance is always positive\n",
    "    y = _generate_rand_point(dimension)\n",
    "    assert jaccard_dist(x, y) >= 0\n",
    "    # distance is symmetric\n",
    "    assert jaccard_dist(x, y) == jaccard_dist(y, x)\n",
    "    # triangle inequality\n",
    "    z = _generate_rand_point(dimension)\n",
    "    assert jaccard_dist(x, y) <= jaccard_dist(x, z) + jaccard_dist(z, y)\n",
    "\n",
    "    print(\"jaccard_dist is right!\")\n",
    "\n",
    "#testing methods\n",
    "test_euclidean()\n",
    "test_manhattan()\n",
    "test_cosine()\n",
    "test_jaccard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c11202d2846b22eec7deaf37ea813ba92a5f75b5344a4d16688175855af7948e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
